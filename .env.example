# Environment
ARBITRIUM_ENV=development

# LLM API Keys (for tournaments)
# LiteLLM reads these environment variables automatically.
# Only set the keys for providers you plan to use.
#
# Provider documentation:
# OpenAI: https://platform.openai.com/api-keys
# Anthropic: https://console.anthropic.com/settings/keys
# Google AI: https://makersuite.google.com/app/apikey
# xAI (Grok): https://console.x.ai/
# Mistral: https://console.mistral.ai/api-keys
# Cohere: https://dashboard.cohere.com/api-keys
# Groq: https://console.groq.com/keys
# Together AI: https://api.together.xyz/settings/api-keys
# Perplexity: https://www.perplexity.ai/settings/api
# DeepSeek: https://platform.deepseek.com/api_keys
# OpenRouter: https://openrouter.ai/keys

# Core providers
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AI...
XAI_API_KEY=xai-...

# Additional providers (uncomment as needed)
# MISTRAL_API_KEY=...
# COHERE_API_KEY=...
# GROQ_API_KEY=gsk_...
# TOGETHER_API_KEY=...
# PERPLEXITY_API_KEY=pplx-...
# DEEPSEEK_API_KEY=sk-...
# OPENROUTER_API_KEY=sk-or-...

# Cloud providers (require additional setup)
# VERTEX_AI_API_KEY=...
# AZURE_API_KEY=...
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-01
# AWS_ACCESS_KEY_ID=...
# AWS_SECRET_ACCESS_KEY=...
# AWS_REGION_NAME=us-east-1

# LiteLLM Configuration
LITELLM_LOG=INFO

# Ollama Configuration
# REQUIRED when using Ollama models (llama3, phi3, gemma3, qwen3)
OLLAMA_BASE_URL=http://localhost:11434
